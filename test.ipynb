{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d88668f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/yopparay/Desktop/jaziri/cellule/project/data', '/home/yopparay/Desktop/jaziri/cellule/project/src', '/home/yopparay/Desktop/jaziri/cellule/project', '/home/yopparay/miniconda3/envs/rocm/lib/python312.zip', '/home/yopparay/miniconda3/envs/rocm/lib/python3.12', '/home/yopparay/miniconda3/envs/rocm/lib/python3.12/lib-dynload', '', '/home/yopparay/miniconda3/envs/rocm/lib/python3.12/site-packages', '/home/yopparay/miniconda3/envs/rocm/lib/python3.12/site-packages/setuptools/_vendor', '/tmp/tmptk7bhk5c']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "from loguru import logger\n",
    "\n",
    "from paths import DATA_DIR, RAW_DATA, SRC_DIR\n",
    "from data.utils import (\n",
    "   \n",
    "    PROCESSED_DATA,\n",
    "    TRANSFORMS_FOLDER,\n",
    "    GOOGLENET_TRAIN_IMAGES_NPY,\n",
    "    GOOGLENET_TRAIN_LABELS_NPY,\n",
    "\n",
    "    GOOGLENET_TEST_IMAGES_NPY,\n",
    "    GOOGLENET_TEST_LABELS_NPY,\n",
    "    \n",
    "    CLASSES_NAMES,\n",
    "    CLASSES_INDEX,\n",
    "    DATA_TRAIN_PATH,\n",
    "    DATA_TESTA_PATH,\n",
    "\n",
    "    show_images,\n",
    "    save_npy,\n",
    "    load_images_from_folders\n",
    ")\n",
    "from data.data_augmentation_transforms import ImageData\n",
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c36c28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18fc79b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-09 19:32:17.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1m======================================================================\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mROCm DIAGNOSTIC TOOL\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1m======================================================================\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m14\u001b[0m - \u001b[1m\n",
      "1. PyTorch GPU Detection:\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.287\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1m   CUDA Available: False\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1m   Device Count: 0\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.289\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m22\u001b[0m - \u001b[33m\u001b[1m   ⚠ PyTorch cannot detect GPU!\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1m\n",
      "2. PyTorch Version & HIP:\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1m   PyTorch Version: 2.6.0+rocm6.1\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1m   HIP Version: 6.1.40091-a8dbc0c19\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1m   ✓ HIP is available (ROCm support)\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1m\n",
      "3. Environment Variables:\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.296\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m60\u001b[0m - \u001b[33m\u001b[1m   HIP_VISIBLE_DEVICES: NOT SET\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.297\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m60\u001b[0m - \u001b[33m\u001b[1m   ROCM_HOME: NOT SET\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1m   HSA_OVERRIDE_GFX_VERSION: 0...\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.299\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1m   PATH: /home/yopparay/miniconda3/envs/rocm/bin:/home/yopparay/miniconda3/condabin:/app/bin:/app/bin:/app/bi...\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.300\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m60\u001b[0m - \u001b[33m\u001b[1m   LD_LIBRARY_PATH: NOT SET\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1m\n",
      "4. System GPU Detection (rocm-smi):\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.306\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m78\u001b[0m - \u001b[33m\u001b[1m   ⚠ rocm-smi not found (ROCm not installed?)\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1m\n",
      "5. GPU Memory:\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m96\u001b[0m - \u001b[33m\u001b[1m   Could not get GPU memory info\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1m\n",
      "6. PyTorch GPU Test:\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m114\u001b[0m - \u001b[33m\u001b[1m   ⚠ No GPU available for testing\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1m\n",
      "======================================================================\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m123\u001b[0m - \u001b[1mSUMMARY & RECOMMENDATIONS\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1m======================================================================\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.315\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m135\u001b[0m - \u001b[33m\u001b[1m\n",
      "    ⚠ ROCm is NOT properly configured\n",
      "    \n",
      "    FIXES TO TRY (in order):\n",
      "    \n",
      "    1. INSTALL/UPDATE ROCm:\n",
      "       pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7\n",
      "       \n",
      "    2. SET ENVIRONMENT VARIABLES:\n",
      "       export HIP_VISIBLE_DEVICES=0\n",
      "       export ROCM_HOME=/opt/rocm\n",
      "       export PATH=/opt/rocm/bin:$PATH\n",
      "       export LD_LIBRARY_PATH=/opt/rocm/lib:$LD_LIBRARY_PATH\n",
      "       \n",
      "    3. CHECK ROCM INSTALLATION:\n",
      "       rocm-smi\n",
      "       \n",
      "    4. VERIFY HIP:\n",
      "       python -c \"import torch; print(torch.version.hip)\"\n",
      "       \n",
      "    5. REINSTALL PYTORCH FOR ROCM:\n",
      "       pip uninstall torch torchvision torchaudio\n",
      "       pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7\n",
      "       \n",
      "    6. RESTART PYTHON/TERMINAL:\n",
      "       Environment variables need to be reloaded\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m167\u001b[0m - \u001b[1m\n",
      "======================================================================\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m168\u001b[0m - \u001b[1mFULL FIX - RUN THESE COMMANDS\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1m======================================================================\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1m\n",
      "# Step 1: Update pip\n",
      "pip install --upgrade pip setuptools\n",
      "\n",
      "# Step 2: Install PyTorch for ROCm\n",
      "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7\n",
      "\n",
      "# Step 3: Verify installation\n",
      "python -c \"import torch; print('CUDA:', torch.cuda.is_available()); print('HIP:', torch.version.hip)\"\n",
      "\n",
      "# Step 4: Test GPU\n",
      "python -c \"x = torch.randn(10).cuda(); print('GPU Test:', x.device)\"\n",
      "\n",
      "# Step 5: Run training\n",
      "python -m src.models\n",
      "\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m188\u001b[0m - \u001b[1m\n",
      "======================================================================\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1mFOR NOW: Use CPU Mode\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m190\u001b[0m - \u001b[1m======================================================================\u001b[0m\n",
      "\u001b[32m2025-12-09 19:32:17.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1m\n",
      "While you fix ROCm, you can still train on CPU (slower):\n",
      "\n",
      "In training script:\n",
      "    device = torch.device(\"cpu\")\n",
      "    batch_size = 2 (reduce for CPU)\n",
      "    num_workers = 0\n",
      "\n",
      "Training will be slow but will work!\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import subprocess\n",
    "import os\n",
    "from loguru import logger\n",
    "\n",
    "logger.info(\"=\"*70)\n",
    "logger.info(\"ROCm DIAGNOSTIC TOOL\")\n",
    "logger.info(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. CHECK IF PYTORCH RECOGNIZES GPU\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"\\n1. PyTorch GPU Detection:\")\n",
    "logger.info(f\"   CUDA Available: {torch.cuda.is_available()}\")\n",
    "logger.info(f\"   Device Count: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    logger.info(f\"   Current Device: {torch.cuda.current_device()}\")\n",
    "    logger.info(f\"   Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    logger.warning(\"   ⚠ PyTorch cannot detect GPU!\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. CHECK PYTORCH VERSION AND HIP SUPPORT\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"\\n2. PyTorch Version & HIP:\")\n",
    "logger.info(f\"   PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "try:\n",
    "    hip_version = torch.version.hip\n",
    "    logger.info(f\"   HIP Version: {hip_version}\")\n",
    "    if hip_version:\n",
    "        logger.info(\"   ✓ HIP is available (ROCm support)\")\n",
    "    else:\n",
    "        logger.warning(\"   ⚠ HIP is NOT available (GPU support missing)\")\n",
    "except:\n",
    "    logger.warning(\"   ⚠ Could not determine HIP version\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. CHECK SYSTEM ENVIRONMENT VARIABLES\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"\\n3. Environment Variables:\")\n",
    "\n",
    "important_vars = [\n",
    "    'HIP_VISIBLE_DEVICES',\n",
    "    'ROCM_HOME',\n",
    "    'HSA_OVERRIDE_GFX_VERSION',\n",
    "    'PATH',\n",
    "    'LD_LIBRARY_PATH'\n",
    "]\n",
    "\n",
    "for var in important_vars:\n",
    "    value = os.environ.get(var, \"NOT SET\")\n",
    "    if value != \"NOT SET\":\n",
    "        logger.info(f\"   {var}: {value[:100]}...\")\n",
    "    else:\n",
    "        logger.warning(f\"   {var}: NOT SET\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. CHECK SYSTEM GPU (rocm-smi)\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"\\n4. System GPU Detection (rocm-smi):\")\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(['rocm-smi'], capture_output=True, text=True, timeout=5)\n",
    "    if result.returncode == 0:\n",
    "        logger.info(\"   rocm-smi output:\")\n",
    "        for line in result.stdout.split('\\n')[:10]:\n",
    "            logger.info(f\"   {line}\")\n",
    "        logger.info(\"   ✓ GPU detected by rocm-smi\")\n",
    "    else:\n",
    "        logger.warning(\"   ⚠ rocm-smi failed\")\n",
    "except FileNotFoundError:\n",
    "    logger.warning(\"   ⚠ rocm-smi not found (ROCm not installed?)\")\n",
    "except subprocess.TimeoutExpired:\n",
    "    logger.warning(\"   ⚠ rocm-smi timeout\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. CHECK GPU MEMORY\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"\\n5. GPU Memory:\")\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(['rocm-smi', '--showmeminfo'], capture_output=True, text=True, timeout=5)\n",
    "    if result.returncode == 0:\n",
    "        logger.info(\"   GPU Memory Info:\")\n",
    "        for line in result.stdout.split('\\n')[:15]:\n",
    "            if line.strip():\n",
    "                logger.info(f\"   {line}\")\n",
    "except:\n",
    "    logger.warning(\"   Could not get GPU memory info\")\n",
    "\n",
    "# ============================================================================\n",
    "# 6. TEST PYTORCH WITH GPU\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"\\n6. PyTorch GPU Test:\")\n",
    "\n",
    "try:\n",
    "    # Create tensor on GPU\n",
    "    if torch.cuda.is_available():\n",
    "        x = torch.randn(10, 10).cuda()\n",
    "        logger.info(f\"   ✓ Tensor created on GPU: {x.device}\")\n",
    "        \n",
    "        # Test computation\n",
    "        y = x @ x.T\n",
    "        logger.info(f\"   ✓ Computation successful\")\n",
    "    else:\n",
    "        logger.warning(\"   ⚠ No GPU available for testing\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"   ✗ GPU test failed: {e}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY & RECOMMENDATIONS\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"\\n\" + \"=\"*70)\n",
    "logger.info(\"SUMMARY & RECOMMENDATIONS\")\n",
    "logger.info(\"=\"*70)\n",
    "\n",
    "if torch.cuda.is_available() and torch.version.hip:\n",
    "    logger.info(\"\"\"\n",
    "    ✓ ROCm is properly configured!\n",
    "    ✓ You can use GPU for training\n",
    "    \n",
    "    In your training script, use:\n",
    "        device = torch.device(\"cuda\")\n",
    "    \"\"\")\n",
    "else:\n",
    "    logger.warning(\"\"\"\n",
    "    ⚠ ROCm is NOT properly configured\n",
    "    \n",
    "    FIXES TO TRY (in order):\n",
    "    \n",
    "    1. INSTALL/UPDATE ROCm:\n",
    "       pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7\n",
    "       \n",
    "    2. SET ENVIRONMENT VARIABLES:\n",
    "       export HIP_VISIBLE_DEVICES=0\n",
    "       export ROCM_HOME=/opt/rocm\n",
    "       export PATH=/opt/rocm/bin:$PATH\n",
    "       export LD_LIBRARY_PATH=/opt/rocm/lib:$LD_LIBRARY_PATH\n",
    "       \n",
    "    3. CHECK ROCM INSTALLATION:\n",
    "       rocm-smi\n",
    "       \n",
    "    4. VERIFY HIP:\n",
    "       python -c \"import torch; print(torch.version.hip)\"\n",
    "       \n",
    "    5. REINSTALL PYTORCH FOR ROCM:\n",
    "       pip uninstall torch torchvision torchaudio\n",
    "       pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7\n",
    "       \n",
    "    6. RESTART PYTHON/TERMINAL:\n",
    "       Environment variables need to be reloaded\n",
    "    \"\"\")\n",
    "\n",
    "# ============================================================================\n",
    "# FULL FIX COMMANDS\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"\\n\" + \"=\"*70)\n",
    "logger.info(\"FULL FIX - RUN THESE COMMANDS\")\n",
    "logger.info(\"=\"*70)\n",
    "\n",
    "logger.info(\"\"\"\n",
    "# Step 1: Update pip\n",
    "pip install --upgrade pip setuptools\n",
    "\n",
    "# Step 2: Install PyTorch for ROCm\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7\n",
    "\n",
    "# Step 3: Verify installation\n",
    "python -c \"import torch; print('CUDA:', torch.cuda.is_available()); print('HIP:', torch.version.hip)\"\n",
    "\n",
    "# Step 4: Test GPU\n",
    "python -c \"x = torch.randn(10).cuda(); print('GPU Test:', x.device)\"\n",
    "\n",
    "# Step 5: Run training\n",
    "python -m src.models\n",
    "\"\"\")\n",
    "\n",
    "logger.info(\"\\n\" + \"=\"*70)\n",
    "logger.info(\"FOR NOW: Use CPU Mode\")\n",
    "logger.info(\"=\"*70)\n",
    "\n",
    "logger.info(\"\"\"\n",
    "While you fix ROCm, you can still train on CPU (slower):\n",
    "\n",
    "In training script:\n",
    "    device = torch.device(\"cpu\")\n",
    "    batch_size = 2 (reduce for CPU)\n",
    "    num_workers = 0\n",
    "\n",
    "Training will be slow but will work!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9902ccaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-09 19:31:09.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1m======================================================================\u001b[0m\n",
      "\u001b[32m2025-12-09 19:31:09.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mROCm (AMD GPU) TRAINING\u001b[0m\n",
      "\u001b[32m2025-12-09 19:31:09.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1m======================================================================\u001b[0m\n",
      "\u001b[32m2025-12-09 19:31:09.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1m\n",
      "Setting up ROCm device...\u001b[0m\n",
      "\u001b[32m2025-12-09 19:31:09.668\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m105\u001b[0m - \u001b[33m\u001b[1m⚠ No GPU detected! Using CPU (training will be SLOW)\u001b[0m\n",
      "\u001b[32m2025-12-09 19:31:09.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m115\u001b[0m - \u001b[1m\n",
      "Loading data...\u001b[0m\n",
      "\u001b[32m2025-12-09 19:31:09.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m✓ Data loaded\u001b[0m\n",
      "\u001b[32m2025-12-09 19:31:09.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1m  Train batches: 1272\u001b[0m\n",
      "\u001b[32m2025-12-09 19:31:09.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1m  Val batches: 109\u001b[0m\n",
      "\u001b[32m2025-12-09 19:31:09.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1m  Test batches: 433\u001b[0m\n",
      "\u001b[32m2025-12-09 19:31:09.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m142\u001b[0m - \u001b[1m\n",
      "Creating model...\u001b[0m\n",
      "\u001b[32m2025-12-09 19:31:09.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mLoading ResNet18 (lightweight for ROCm)...\u001b[0m\n",
      "\u001b[32m2025-12-09 19:31:09.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m161\u001b[0m - \u001b[1m✓ Model created and moved to device\u001b[0m\n",
      "\u001b[32m2025-12-09 19:31:09.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1m  Total parameters: 11,309,125\u001b[0m\n",
      "\u001b[32m2025-12-09 19:31:09.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m167\u001b[0m - \u001b[1m  Trainable parameters: 11,309,125\u001b[0m\n",
      "\u001b[32m2025-12-09 19:31:09.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1m\n",
      "Setting up training...\u001b[0m\n",
      "\u001b[32m2025-12-09 19:31:09.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m207\u001b[0m - \u001b[1mOptimizer: Adam (lr=1e-4)\u001b[0m\n",
      "\u001b[32m2025-12-09 19:31:09.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m208\u001b[0m - \u001b[1mLoss: CrossEntropyLoss\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from loguru import logger\n",
    "\n",
    "import os\n",
    "\n",
    "# ============================================================================\n",
    "# ROCm SPECIFIC SETTINGS\n",
    "# ============================================================================\n",
    "\n",
    "# Set environment variables for ROCm stability\n",
    "os.environ['HSA_OVERRIDE_GFX_VERSION'] = '0'  # Auto-detect GPU\n",
    "os.environ['PYTORCH_HIP_ALLOC_CONF'] = ':16:8'  # Memory pooling for stability\n",
    "\n",
    "logger.info(\"=\"*70)\n",
    "logger.info(\"ROCm (AMD GPU) TRAINING\")\n",
    "logger.info(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    batch_count = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(loader):\n",
    "        try:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            batch_count += 1\n",
    "            \n",
    "            # Log every 5 batches\n",
    "            if (batch_idx + 1) % 5 == 0:\n",
    "                logger.info(f\"    Batch {batch_idx + 1}: Loss = {loss.item():.4f}\")\n",
    "        \n",
    "        except RuntimeError as e:\n",
    "            logger.error(f\"ERROR in batch {batch_idx}: {e}\")\n",
    "            logger.error(\"Try reducing batch_size or using CPU mode\")\n",
    "            raise\n",
    "\n",
    "    return total_loss / batch_count if batch_count > 0 else 0\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batch_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            batch_count += 1\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    return total_loss / batch_count if batch_count > 0 else 0, accuracy\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # ====================================================================\n",
    "    # STEP 1: SETUP DEVICE (ROCm)\n",
    "    # ====================================================================\n",
    "    \n",
    "    logger.info(\"\\nSetting up ROCm device...\")\n",
    "    \n",
    "    # Check for ROCm/AMD GPU\n",
    "    if torch.cuda.is_available():\n",
    "        logger.info(\"✓ CUDA/ROCm is available\")\n",
    "        device = torch.device(\"cuda\")\n",
    "        logger.info(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        \n",
    "        # Get GPU properties for ROCm\n",
    "        props = torch.cuda.get_device_properties(0)\n",
    "        logger.info(f\"GPU Memory: {props.total_memory / 1e9:.2f} GB\")\n",
    "        logger.info(f\"GPU Architecture: {props.name}\")\n",
    "    else:\n",
    "        logger.warning(\"⚠ No GPU detected! Using CPU (training will be SLOW)\")\n",
    "        device = torch.device(\"cpu\")\n",
    "    \n",
    "    # Clear GPU cache\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # ====================================================================\n",
    "    # STEP 2: LOAD DATA\n",
    "    # ====================================================================\n",
    "    \n",
    "    logger.info(\"\\nLoading data...\")\n",
    "    \n",
    "    # ROCm optimal settings:\n",
    "    # - batch_size: 8-16 (smaller than CUDA due to memory management differences)\n",
    "    # - num_workers: 2-4 (helps with data loading on ROCm)\n",
    "    \n",
    "    data = ImageData(\n",
    "        train_dir=DATA_TRAIN_PATH,\n",
    "        test_dir=DATA_TESTA_PATH,\n",
    "        batch_size=8,           # ← Smaller for ROCm stability\n",
    "        num_workers=2,          # ← Help ROCm with data loading\n",
    "        balance_classes=True\n",
    "    )\n",
    "    \n",
    "    train_loader = data.train_loader()\n",
    "    val_loader = data.val_loader()\n",
    "    test_loader = data.test_loader()\n",
    "    \n",
    "    logger.info(f\"✓ Data loaded\")\n",
    "    logger.info(f\"  Train batches: {len(train_loader)}\")\n",
    "    logger.info(f\"  Val batches: {len(val_loader)}\")\n",
    "    logger.info(f\"  Test batches: {len(test_loader)}\")\n",
    "    \n",
    "    # ====================================================================\n",
    "    # STEP 3: CREATE MODEL\n",
    "    # ====================================================================\n",
    "    \n",
    "    logger.info(\"\\nCreating model...\")\n",
    "    \n",
    "    # For ROCm, ResNet50 might be too heavy\n",
    "    # Start with ResNet18 for stability\n",
    "    logger.info(\"Loading ResNet18 (lightweight for ROCm)...\")\n",
    "    \n",
    "    try:\n",
    "        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        \n",
    "        # Modify last layer for 5 classes\n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 256),  # Smaller hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 5)\n",
    "        )\n",
    "        \n",
    "        model = model.to(device)\n",
    "        logger.info(\"✓ Model created and moved to device\")\n",
    "        \n",
    "        # Count parameters\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        logger.info(f\"  Total parameters: {total_params:,}\")\n",
    "        logger.info(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "        \n",
    "    except RuntimeError as e:\n",
    "        logger.error(f\"Error loading model: {e}\")\n",
    "        logger.error(\"Trying ResNet18 without pretrained weights...\")\n",
    "        model = models.resnet18(weights=None)\n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 5)\n",
    "        )\n",
    "        model = model.to(device)\n",
    "    \n",
    "    # ====================================================================\n",
    "    # STEP 4: SETUP TRAINING\n",
    "    # ====================================================================\n",
    "    \n",
    "    logger.info(\"\\nSetting up training...\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Optimizer for ROCm\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=1e-4,\n",
    "        weight_decay=1e-4,\n",
    "        amsgrad=False  # ROCm sometimes has issues with AMSGrad\n",
    "    )\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Optimizer: Adam (lr=1e-4)\")\n",
    "    logger.info(f\"Loss: CrossEntropyLoss\")\n",
    "    \n",
    "    # ====================================================================\n",
    "    # STEP 5: TRAINING LOOP\n",
    "    # ====================================================================\n",
    "    \n",
    "#     logger.info(\"\\n\" + \"=\"*70)\n",
    "#     logger.info(\"STARTING TRAINING ON ROCm\")\n",
    "#     logger.info(\"=\"*70)\n",
    "    \n",
    "#     EPOCHS = 10\n",
    "#     best_val_loss = float('inf')\n",
    "#     patience = 3\n",
    "#     patience_counter = 0\n",
    "    \n",
    "#     for epoch in range(EPOCHS):\n",
    "#         logger.info(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "        \n",
    "#         # Clear GPU cache before epoch (important for ROCm)\n",
    "#         torch.cuda.empty_cache()\n",
    "        \n",
    "#         if torch.cuda.is_available():\n",
    "#             allocated = torch.cuda.memory_allocated() / 1e9\n",
    "#             logger.info(f\"GPU Memory at start: {allocated:.2f} GB\")\n",
    "        \n",
    "#         # Train\n",
    "#         try:\n",
    "#             train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "#             logger.info(f\"  Train Loss: {train_loss:.4f}\")\n",
    "#         except Exception as e:\n",
    "#             logger.error(f\"Training error: {e}\")\n",
    "#             break\n",
    "        \n",
    "#         # Validate\n",
    "#         try:\n",
    "#             val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "#             logger.info(f\"  Val Loss: {val_loss:.4f}\")\n",
    "#             logger.info(f\"  Val Accuracy: {val_acc*100:.2f}%\")\n",
    "#         except Exception as e:\n",
    "#             logger.error(f\"Validation error: {e}\")\n",
    "#             break\n",
    "        \n",
    "#         # Learning rate scheduling\n",
    "#         scheduler.step(val_loss)\n",
    "        \n",
    "#         # Early stopping with patience\n",
    "#         if val_loss < best_val_loss:\n",
    "#             best_val_loss = val_loss\n",
    "#             patience_counter = 0\n",
    "#             torch.save(model.state_dict(), 'best_model.pth')\n",
    "#             logger.info(\"  ✓ Best model saved\")\n",
    "#         else:\n",
    "#             patience_counter += 1\n",
    "#             if patience_counter >= patience:\n",
    "#                 logger.info(f\"Early stopping at epoch {epoch+1}\")\n",
    "#                 break\n",
    "        \n",
    "#         # Clear cache between epochs\n",
    "#         torch.cuda.empty_cache()\n",
    "    \n",
    "#     # ====================================================================\n",
    "#     # STEP 6: TEST\n",
    "#     # ====================================================================\n",
    "    \n",
    "#     logger.info(\"\\n\" + \"=\"*70)\n",
    "#     logger.info(\"TESTING ON ROCm\")\n",
    "#     logger.info(\"=\"*70)\n",
    "    \n",
    "#     # Load best model\n",
    "#     try:\n",
    "#         model.load_state_dict(torch.load('best_model.pth'))\n",
    "#         logger.info(\"✓ Loaded best model\")\n",
    "#     except:\n",
    "#         logger.warning(\"Could not load best model, using current\")\n",
    "    \n",
    "#     test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
    "#     logger.info(f\"Test Loss: {test_loss:.4f}\")\n",
    "#     logger.info(f\"Test Accuracy: {test_acc*100:.2f}%\")\n",
    "    \n",
    "#     logger.info(\"\\n✓ Training complete!\")\n",
    "\n",
    "\n",
    "# # ============================================================================\n",
    "# # ROCm TROUBLESHOOTING\n",
    "# # ============================================================================\n",
    "\n",
    "# \"\"\"\n",
    "# If you still get segmentation fault on ROCm:\n",
    "\n",
    "# 1. REDUCE BATCH SIZE FURTHER:\n",
    "#    batch_size = 4\n",
    "   \n",
    "# 2. USE CPU MODE (for debugging):\n",
    "#    device = torch.device(\"cpu\")\n",
    "   \n",
    "# 3. UPDATE ROCm:\n",
    "#    pip install --upgrade torch torchvision torchaudio\n",
    "   \n",
    "# 4. CHECK VRAM:\n",
    "#    rocm-smi\n",
    "   \n",
    "# 5. DISABLE PRETRAINED WEIGHTS:\n",
    "#    model = models.resnet18(weights=None)\n",
    "   \n",
    "# 6. MONOLITHIC KERNEL (for ROCm stability):\n",
    "#    export PYTORCH_KERNEL_TYPE=monolithic\n",
    "   \n",
    "# 7. USE SIMPLER MODEL:\n",
    "#    Instead of ResNet, try:\n",
    "#    model = models.mobilenet_v2(weights=None)\n",
    "   \n",
    "# 8. CPU OFFLOADING:\n",
    "#    optimizer = optim.SGD(model.parameters(), lr=1e-4)\n",
    "#    # SGD is more stable than Adam on ROCm\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2cd6f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return total_loss / len(loader), accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "204b56ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "190494f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    \n",
    "\n",
    "data = ImageData(\n",
    "    train_dir = DATA_TRAIN_PATH,\n",
    "    test_dir = DATA_TESTA_PATH,\n",
    "    batch_size=32,\n",
    "    num_workers=4,\n",
    "    balance_classes=True\n",
    ")\n",
    "\n",
    "train_loader = data.train_loader()\n",
    "val_loader = data.val_loader()\n",
    "test_loader = data.test_loader()\n",
    "\n",
    "dataset = data.train_dataset\n",
    "\n",
    "\n",
    "num_features = model.fc.in_features\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(512, 5)\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(\n",
    "    model.fc.parameters(),\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f}\")\n",
    "    print(f\"  Val Acc:    {val_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b87fc4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.version.hip  # should be set for ROCm\n",
    "torch.cuda.is_available()  # should be True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9556d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Initialize your data\n",
    "    data = ImageData(\n",
    "        train_dir=DATA_TRAIN_PATH,\n",
    "        test_dir=DATA_TESTA_PATH,\n",
    "        batch_size=32,\n",
    "        num_workers=4,\n",
    "        balance_classes=True\n",
    "    )\n",
    "\n",
    "    train_loader = data.train_loader()\n",
    "    val_loader = data.val_loader()\n",
    "    test_loader = data.test_loader()\n",
    "\n",
    "    # -------------------------------\n",
    "    # Initialize model\n",
    "    # -------------------------------\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "    # Replace the final fully connected layer\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(num_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(512, 5)  # Replace 5 with your number of classes\n",
    "    )\n",
    "\n",
    "    model = model.to(device)  # Move entire model to device\n",
    "\n",
    "    # Set all layers trainable (optional)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),  # can optimize all parameters\n",
    "        lr=1e-4,\n",
    "        weight_decay=1e-4\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # Training loop\n",
    "    # -------------------------------\n",
    "    EPOCHS = 1\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"  Val Loss:   {val_loss:.4f}\")\n",
    "        print(f\"  Val Acc:    {val_acc*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rocm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
